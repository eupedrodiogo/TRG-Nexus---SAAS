
import streamlit as st
import pandas as pd
import re
from rapidfuzz import fuzz, process
from datetime import datetime
import io
import unicodedata

# Configura√ß√£o da p√°gina
st.set_page_config(
    page_title="Correspond√™ncia Protheus-Tasy",
    page_icon="üîó",
    layout="wide"
)

# CSS personalizado para melhor apar√™ncia
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        font-weight: bold;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 1rem;
    }
    .sub-header {
        font-size: 1.2rem;
        color: #666;
        text-align: center;
        margin-bottom: 2rem;
    }
    .success-box {
        padding: 1rem;
        background-color: #d4edda;
        border: 1px solid #c3e6cb;
        border-radius: 5px;
        color: #155724;
        margin: 1rem 0;
    }
    .error-box {
        padding: 1rem;
        background-color: #f8d7da;
        border: 1px solid #f5c6cb;
        border-radius: 5px;
        color: #721c24;
        margin: 1rem 0;
    }
    .info-box {
        padding: 1rem;
        background-color: #d1ecf1;
        border: 1px solid #bee5eb;
        border-radius: 5px;
        color: #0c5460;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

# Regex pr√©-compilados para performance
RE_SPECIAL = re.compile(r'[^a-z0-9\s]')
RE_SPACES = re.compile(r'\s+')

@st.cache_data(show_spinner=False)
def get_template_excel():
    """Gera um arquivo Excel de modelo com as abas e colunas esperadas."""
    buf = io.BytesIO()
    with pd.ExcelWriter(buf, engine="openpyxl") as writer:
        pd.DataFrame(columns=["Codigo", "Descricao"]).to_excel(
            writer, sheet_name="Protheus", index=False, startrow=1
        )
        pd.DataFrame(columns=["C√≥digo do material", "Descri√ß√£o do Material Tasy"]).to_excel(
            writer, sheet_name="De Para Almoxarifado", index=False
        )
    buf.seek(0)
    return buf.getvalue()

def normalize_text(text):
    """
    Normaliza o texto para melhorar a compara√ß√£o:
    - Remove caracteres especiais
    - Converte para min√∫sculas
    - Remove espa√ßos extras
    """
    if pd.isna(text):
        return ""
    text = str(text).lower()
    # Remove caracteres especiais e espa√ßos m√∫ltiplos usando regex pr√©-compilada
    text = RE_SPECIAL.sub(" ", text)
    text = RE_SPACES.sub(" ", text)
    return text.strip()

def validate_excel_file(uploaded_file):
    """
    Valida o arquivo Excel carregado.
    Retorna (success, message, df_protheus, df_de_para)
    """
    try:
        # Ler o arquivo Excel
        xls = pd.ExcelFile(uploaded_file)
        # Verificar se as abas existem (case-insensitive)
        sheet_names_lower = {name.lower(): name for name in xls.sheet_names}
        if 'protheus' not in sheet_names_lower:
            return False, "‚ùå Aba 'Protheus' n√£o encontrada no arquivo.", None, None
        if 'de para almoxarifado' not in sheet_names_lower:
            return False, "‚ùå Aba 'De Para Almoxarifado' n√£o encontrada no arquivo.", None, None
        # Ler as abas
        protheus_sheet = sheet_names_lower['protheus']
        de_para_sheet = sheet_names_lower['de para almoxarifado']
        # Ler aba Protheus (header na linha 1) - limitar para evitar problemas de mem√≥ria
        try:
            df_protheus = pd.read_excel(uploaded_file, sheet_name=protheus_sheet, header=1, nrows=5000)
        except:
            df_protheus = pd.read_excel(uploaded_file, sheet_name=protheus_sheet, header=1)
        # Ler aba De Para Almoxarifado - limitar para evitar problemas de mem√≥ria
        try:
            df_de_para = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=0, nrows=2000)
        except:
            df_de_para = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=0)
        # Remove acentos de strings (para reconhecimento robusto de cabe√ßalhos)
        def strip_accents(s: str) -> str:
            if s is None:
                return ""
            s = str(s)
            return ''.join(c for c in unicodedata.normalize('NFKD', s) if not unicodedata.combining(c))
        # Validar colunas obrigat√≥rias - case insensitive
        protheus_cols = {str(col).strip().lower(): col for col in df_protheus.columns}
        if 'descricao' not in protheus_cols:
            return False, "‚ùå Coluna 'Descricao' n√£o encontrada na aba Protheus.", None, None
        if 'codigo' not in protheus_cols:
            return False, "‚ùå Coluna 'Codigo' n√£o encontrada na aba Protheus.", None, None
        protheus_cols = {strip_accents(str(col)).strip().lower(): col for col in df_protheus.columns}
        # Fallback de cabe√ßalho: tentar header=0 se n√£o encontrar as colunas
        if 'descricao' not in protheus_cols or 'codigo' not in protheus_cols:
            try:
                df_protheus_alt = pd.read_excel(uploaded_file, sheet_name=protheus_sheet, header=0, nrows=5000)
            except:
                df_protheus_alt = pd.read_excel(uploaded_file, sheet_name=protheus_sheet, header=0)
            protheus_cols_alt = {strip_accents(str(col)).strip().lower(): col for col in df_protheus_alt.columns}
            if 'descricao' in protheus_cols_alt and 'codigo' in protheus_cols_alt:
                df_protheus = df_protheus_alt
                protheus_cols = protheus_cols_alt
        if 'descricao' not in protheus_cols:
            return False, "‚ùå Coluna 'Descricao' n√£o encontrada na aba Protheus.", None, None
        if 'codigo' not in protheus_cols:
            return False, "‚ùå Coluna 'Codigo' n√£o encontrada na aba Protheus.", None, None
        # Mapear colunas da aba De Para (removendo acentos e normalizando)
        de_para_cols = {strip_accents(str(col)).strip().lower(): col for col in df_de_para.columns}
        # Procurar coluna de c√≥digo e de descri√ß√£o do Tasy

        codigo_tasy_col = None
        for norm, original in de_para_cols.items():
            if 'codigo' in norm and 'material' in norm:
                codigo_tasy_col = original
                break
        # Fallback: tentar outra linha de cabe√ßalho (header=1) se n√£o encontrar
        if codigo_tasy_col is None:
            try:
                df_de_para_alt = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=1, nrows=2000)
            except:
                df_de_para_alt = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=1)
            de_para_cols_alt = {strip_accents(str(col)).strip().lower(): col for col in df_de_para_alt.columns}
            for norm, original in de_para_cols_alt.items():
                if 'codigo' in norm and 'material' in norm:
                    codigo_tasy_col = original
                    df_de_para = df_de_para_alt
                    de_para_cols = de_para_cols_alt
                    break
        # Fallback mais flex√≠vel: aceitar qualquer coluna com 'codigo'
        if codigo_tasy_col is None:
            for norm, original in de_para_cols.items():
                if 'codigo' in norm:
                    codigo_tasy_col = original
                    break
        if codigo_tasy_col is None:
            return False, "‚ùå Coluna 'C√≥digo do material' n√£o encontrada na aba De Para Almoxarifado.", None, None
        desc_tasy_col = None
        for norm, original in de_para_cols.items():
            if 'descricao' in norm and 'tasy' in norm:
                desc_tasy_col = original
                break
        # Fallback: tentar outra linha de cabe√ßalho (header=1) se n√£o encontrar
        if desc_tasy_col is None:
            try:
                df_de_para_alt = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=1, nrows=2000)
            except:
                df_de_para_alt = pd.read_excel(uploaded_file, sheet_name=de_para_sheet, header=1)
            de_para_cols_alt = {strip_accents(str(col)).strip().lower(): col for col in df_de_para_alt.columns}
            for norm, original in de_para_cols_alt.items():
                if 'descricao' in norm and 'tasy' in norm:
                    desc_tasy_col = original
                    df_de_para = df_de_para_alt
                    de_para_cols = de_para_cols_alt
                    break
        # Fallback mais flex√≠vel: aceitar qualquer coluna com 'descricao'
        if desc_tasy_col is None:
            for norm, original in de_para_cols.items():
                if 'descricao' in norm:
                    desc_tasy_col = original
                    break
        if desc_tasy_col is None:
            return False, "‚ùå Coluna 'Descri√ß√£o do material (Tasy)' n√£o encontrada na aba De Para Almoxarifado.", None, None
        # Padronizar nomes das colunas
        df_protheus = df_protheus.rename(columns={
            protheus_cols['codigo']: 'Codigo',
            protheus_cols['descricao']: 'Descricao'
        })
        df_de_para = df_de_para.rename(columns={
            codigo_tasy_col: 'Codigo_Tasy',
            desc_tasy_col: 'Descricao_Tasy'
        })
        # Garantir tipo consistente para C√≥digo
        if 'Codigo' in df_protheus.columns:
            df_protheus['Codigo'] = df_protheus['Codigo'].astype(str)
        if 'Codigo_Tasy' in df_de_para.columns:
            df_de_para['Codigo_Tasy'] = df_de_para['Codigo_Tasy'].astype(str)
        # Adicionar mensagem sobre limita√ß√£o se aplic√°vel
        info_msg = "‚úÖ Arquivo validado com sucesso!"
        if len(df_protheus) >= 5000:
            info_msg += f" (Limitado a {len(df_protheus)} itens Protheus para performance)"
        if len(df_de_para) >= 2000:
            info_msg += f" (Limitado a {len(df_de_para)} itens Tasy para performance)"
        return True, info_msg, df_protheus, df_de_para
    except Exception as e:
        return False, f"‚ùå Erro ao ler o arquivo: {str(e)}", None, None

@st.cache_data(show_spinner=False)
def compute_matches(protheus_descriptions, protheus_codes, protheus_original, tasy_norm_list, tasy_orig_list, threshold):
    """Computa correspond√™ncias com cache e sem componentes visuais para performance."""
    results = []
    for tasy_desc_norm, tasy_desc in zip(tasy_norm_list, tasy_orig_list):
        matches = process.extract(
            tasy_desc_norm,
            protheus_descriptions,
            scorer=fuzz.token_sort_ratio,
            limit=3,  # top 3 para detectar m√∫ltiplas correspond√™ncias
            score_cutoff=threshold  # evita c√°lculos abaixo do limiar
        )
        if matches:
            best_match = matches[0]
            best_match_idx = best_match[2]
            score = best_match[1]
            revisao_obrigatoria = False
            if len(matches) > 1:
                score_diff = matches[0][1] - matches[1][1]
                if score_diff < 5:
                    revisao_obrigatoria = True
            results.append({
                'Codigo_Protheus': str(protheus_codes[best_match_idx]),
                'Descricao_Protheus': protheus_original[best_match_idx],
                'Descricao_Tasy': tasy_desc,
                'Score_Similaridade': round(score, 2),
                'Revisao_Obrigatoria': '‚ö†Ô∏è SIM' if revisao_obrigatoria else 'N√ÉO'
            })
    return pd.DataFrame(results)

def find_matches(df_protheus, df_de_para, threshold):
    """
    Executa compara√ß√£o sequencial e precisa entre abas:
    1) Compara 'Codigo_Tasy' (De Para) com 'Codigo' (Protheus)
    2) Para c√≥digos encontrados, compara 'Descri√ß√£o do material Tasy' com 'Descricao' usando similaridade
    """
    # Filtrar linhas v√°lidas
    df_protheus_clean = df_protheus.dropna(subset=['Codigo', 'Descricao']).copy()
    df_de_para_clean = df_de_para.dropna(subset=['Codigo_Tasy', 'Descricao_Tasy']).copy()

    # Normaliza√ß√£o das descri√ß√µes
    df_protheus_clean['Descricao_Normalizada'] = df_protheus_clean['Descricao'].apply(normalize_text)
    df_de_para_clean['Descricao_Tasy_Normalizada'] = df_de_para_clean['Descricao_Tasy'].apply(normalize_text)

    # Mapear c√≥digo -> descri√ß√£o (normalizada e original)
    code_to_desc_norm = dict(zip(df_protheus_clean['Codigo'].astype(str), df_protheus_clean['Descricao_Normalizada']))
    code_to_desc_orig = dict(zip(df_protheus_clean['Codigo'].astype(str), df_protheus_clean['Descricao']))

    results = []
    with st.spinner("üîé Comparando por c√≥digo e descri√ß√£o..."):
        for _, row in df_de_para_clean.iterrows():
            codigo_tasy = str(row['Codigo_Tasy'])
            desc_tasy_orig = row['Descricao_Tasy']
            desc_tasy_norm = row['Descricao_Tasy_Normalizada']

            if codigo_tasy in code_to_desc_norm:
                desc_prot_norm = code_to_desc_norm[codigo_tasy]
                desc_prot_orig = code_to_desc_orig[codigo_tasy]
                score = fuzz.token_sort_ratio(desc_tasy_norm, desc_prot_norm)
                results.append({
                    'Codigo_Tasy': codigo_tasy,
                    'Codigo_Protheus': codigo_tasy,
                    'Status_Codigo': 'OK',
                    'Descricao_Tasy': desc_tasy_orig,
                    'Descricao_Protheus': desc_prot_orig,
                    'Score_Similaridade': round(score, 2),
                    'Revisao_Obrigatoria': '‚ö†Ô∏è SIM' if score < threshold else 'N√ÉO'
                })
            else:
                results.append({
                    'Codigo_Tasy': codigo_tasy,
                    'Codigo_Protheus': '',
                    'Status_Codigo': 'N√£o encontrado',
                    'Descricao_Tasy': desc_tasy_orig,
                    'Descricao_Protheus': '',
                    'Score_Similaridade': 0.0,
                    'Revisao_Obrigatoria': '‚ö†Ô∏è SIM'
                })

    return pd.DataFrame(results)

# Interface principal
st.markdown('<div class="main-header">üîó Correspond√™ncia Inteligente Protheus-Tasy</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-header">Sistema de correspond√™ncia automatizada entre itens dos sistemas Protheus e Tasy</div>', unsafe_allow_html=True)

# Se√ß√£o de upload
st.markdown("### üì§ 1. Upload do Arquivo")
uploaded_file = st.file_uploader(
    "Selecione o arquivo Excel (.xls, .xlsx)",
    type=['xls', 'xlsx'],
    help="O arquivo deve conter as abas 'Protheus' e 'De Para Almoxarifado'"
)
# Oferecer modelo de arquivo quando nenhum upload foi feito
if uploaded_file is None:
    st.download_button(
        "üìÑ Baixar modelo Excel",
        data=get_template_excel(),
        file_name="modelo_protheus_tasy.xlsx",
        mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
        help="Modelo com as abas e colunas corretamente nomeadas para uso no sistema"
    )

if uploaded_file is not None:
    # Validar o arquivo
    with st.spinner("üîç Validando arquivo..."):
        success, message, df_protheus, df_de_para = validate_excel_file(uploaded_file)
    
    if success:
        st.markdown(f'<div class="success-box">{message}</div>', unsafe_allow_html=True)
        
        # Mostrar pr√©-visualiza√ß√£o das abas
        st.markdown("### üëÄ 2. Pr√©-visualiza√ß√£o dos Dados")
        
        col1, col2 = st.columns(2)
        
        with col1:
            st.markdown("**Aba Protheus**")
            st.dataframe(
                df_protheus[['Codigo', 'Descricao']].head(10),
                width='stretch'
            )
            st.caption(f"Total de itens: {len(df_protheus)}")
        
        with col2:
            st.markdown("**Aba De Para Almoxarifado**")
            st.dataframe(
                df_de_para[['Codigo_Tasy', 'Descricao_Tasy']].head(10),
                width='stretch'
            )
            st.caption(f"Total de itens: {len(df_de_para)}")
        
        # Configura√ß√£o de correspond√™ncia
        st.markdown("### ‚öôÔ∏è 3. Configura√ß√£o da Correspond√™ncia")

        # Guarda: impedir processamento com dados vazios
        has_protheus_items = df_protheus['Descricao'].notna().any()
        has_tasy_items = df_de_para[['Codigo_Tasy','Descricao_Tasy']].notna().all(axis=1).any()

        if not (has_protheus_items and has_tasy_items):
            st.markdown(
                '<div class="error-box">üìÑ O arquivo est√° vazio nas abas necess√°rias. Preencha o modelo com itens nas colunas exigidas antes de processar.</div>',
                unsafe_allow_html=True
            )
            st.download_button(
                "üìÑ Baixar modelo Excel",
                data=get_template_excel(),
                file_name="modelo_protheus_tasy.xlsx",
                mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                help="Modelo com as abas e colunas corretamente nomeadas para uso no sistema"
            )
            st.stop()
        
        threshold = st.slider(
            "Limiar de Similaridade (%)",
            min_value=50,
            max_value=100,
            value=80,
            step=5,
            help="Apenas correspond√™ncias com score acima deste valor ser√£o exibidas"
        )
        
        # Bot√£o para iniciar correspond√™ncia
        if st.button("üöÄ Iniciar Correspond√™ncia", type="primary"):
            st.markdown("### üîÑ 4. Processamento")
            
            with st.spinner("üîÑ Processando correspond√™ncias..."):
                df_matches = find_matches(df_protheus, df_de_para, threshold)
            
            if len(df_matches) > 0:
                st.markdown(f'<div class="success-box">‚úÖ Processamento conclu√≠do! {len(df_matches)} correspond√™ncias encontradas.</div>', unsafe_allow_html=True)
                
                # Estat√≠sticas
                st.markdown("### üìä 5. Estat√≠sticas")
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    st.metric("Total de Correspond√™ncias", len(df_matches))
                
                with col2:
                    revisao_count = len(df_matches[df_matches['Revisao_Obrigatoria'] == '‚ö†Ô∏è SIM'])
                    st.metric("Revis√£o Obrigat√≥ria", revisao_count)
                
                with col3:
                    avg_score = df_matches['Score_Similaridade'].mean()
                    st.metric("Score M√©dio", f"{avg_score:.1f}%")
                
                with col4:
                    high_confidence = len(df_matches[df_matches['Score_Similaridade'] >= 90])
                    st.metric("Alta Confian√ßa (‚â•90%)", high_confidence)
                
                # Filtros
                st.markdown("### üîç 6. Filtros e Visualiza√ß√£o")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    show_only_review = st.checkbox("Mostrar apenas itens para revis√£o", value=False)
                
                with col2:
                    min_score_filter = st.slider(
                        "Filtrar por score m√≠nimo",
                        min_value=0,
                        max_value=100,
                        value=threshold,
                        step=5
                    )
                
                # Aplicar filtros
                df_filtered = df_matches[df_matches['Score_Similaridade'] >= min_score_filter].copy()
                
                if show_only_review:
                    df_filtered = df_filtered[df_filtered['Revisao_Obrigatoria'] == '‚ö†Ô∏è SIM']
                
                # Ordenar por score (decrescente)
                df_filtered = df_filtered.sort_values('Score_Similaridade', ascending=False)
                
                # Exibir tabela interativa
                st.markdown("### üìã 7. Resultados")
                
                # Destacar itens para revis√£o
                def highlight_review(row):
                    if row['Revisao_Obrigatoria'] == '‚ö†Ô∏è SIM':
                        return ['background-color: #fff3cd'] * len(row)
                    return [''] * len(row)
                
                st.dataframe(
                    df_filtered.style.apply(highlight_review, axis=1),
                    use_container_width=True,
                    height=400
                )
                
                st.caption(f"Exibindo {len(df_filtered)} de {len(df_matches)} correspond√™ncias")
                
                # Exporta√ß√£o
                st.markdown("### üíæ 8. Exporta√ß√£o")
                
                # Gerar nome do arquivo com timestamp
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"correspondencias_{timestamp}.xlsx"
                
                # Criar arquivo Excel em mem√≥ria
                output = io.BytesIO()
                with pd.ExcelWriter(output, engine='openpyxl') as writer:
                    df_filtered.to_excel(writer, index=False, sheet_name='Correspond√™ncias')
                
                excel_data = output.getvalue()
                
                st.download_button(
                    label="üì• Baixar Correspond√™ncias (Excel)",
                    data=excel_data,
                    file_name=filename,
                    mime="application/vnd.openxmlformats-officedocument.spreadsheetml.sheet"
                )
                
                st.markdown(f'<div class="info-box">üí° O arquivo ser√° salvo como: <strong>{filename}</strong></div>', unsafe_allow_html=True)
                
            else:
                st.markdown('<div class="error-box">‚ö†Ô∏è Nenhuma correspond√™ncia encontrada com o limiar atual. Verifique se h√° dados nas abas e, se necess√°rio, reduza o limiar de similaridade.</div>', unsafe_allow_html=True)
    
    else:
        st.markdown(f'<div class="error-box">{message}</div>', unsafe_allow_html=True)

else:
    # Instru√ß√µes quando nenhum arquivo foi carregado
    st.markdown("""
    <div class="info-box">
        <h4>üìù Instru√ß√µes de Uso:</h4>
        <ol>
            <li>Fa√ßa upload de um arquivo Excel contendo as abas <strong>'Protheus'</strong> e <strong>'De Para Almoxarifado'</strong></li>
            <li>Aba <strong>De Para Almoxarifado</strong> deve conter as colunas: <strong>C√≥digo do material</strong> e <strong>Descri√ß√£o do Material Tasy</strong></li>
            <li>Ajuste o limiar de similaridade conforme necess√°rio (padr√£o: 80%)</li>
            <li>Clique em <strong>Iniciar Correspond√™ncia</strong> para processar</li>
            <li>Revise os resultados e baixe o arquivo final</li>
        </ol>
        
        <h4>‚ÑπÔ∏è Sobre o Sistema:</h4>
        <ul>
            <li><strong>Algoritmo de Correspond√™ncia:</strong> Utiliza RapidFuzz para compara√ß√£o textual avan√ßada</li>
            <li><strong>Pr√©-processamento:</strong> Normaliza√ß√£o de texto, remo√ß√£o de caracteres especiais</li>
            <li><strong>Revis√£o Obrigat√≥ria:</strong> Itens com m√∫ltiplas correspond√™ncias similares s√£o marcados automaticamente</li>
            <li><strong>Exporta√ß√£o:</strong> Gera arquivo Excel contendo apenas as correspond√™ncias relevantes</li>
        </ul>
    </div>
    """, unsafe_allow_html=True)

# Rodap√©
st.markdown("---")
st.markdown(
    "<div style='text-align: center; color: #666;'>Desenvolvido com ‚ù§Ô∏è usando Streamlit</div>",
    unsafe_allow_html=True
)